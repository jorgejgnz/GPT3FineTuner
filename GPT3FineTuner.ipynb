{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80e3257c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import openai\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9604b911",
   "metadata": {},
   "source": [
    "## Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "189f398e",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_ai_api_key = \"{YOUR-OPENAI-API-KEY}\"\n",
    "org_id = \"{YOUR-ORGANIZATION-ID}\"\n",
    "\n",
    "openai.api_key = open_ai_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4e7569",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6dc8dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected CSV content:\n",
    "#    Human;AI\n",
    "#    Hello;Hi, I'm an AI\n",
    "#    Open the pod bay doors please;No\n",
    "#    Open the pod bay doors!;Well, if you insist\n",
    "#    <human_questions>;<ai_answers>\n",
    "#    ###;###\n",
    "#    Good morning;Hey\n",
    "#    Can you read me the news?;No, I can't\n",
    "#    Is there something you can do?;You should know\n",
    "#    Oh okey;Yeah\n",
    "#    <human_questions>;<ai_answers>\n",
    "\n",
    "def csv_to_df_list(csv_path, csv_sep=';', df_sep=\"###\", encoding='utf-8'):\n",
    "\n",
    "    df = pd.read_csv(csv_path, sep=csv_sep, encoding=encoding)\n",
    "    df = df.reset_index()\n",
    "\n",
    "    splitted_df = []\n",
    "    subdf = pd.DataFrame([], columns=[df.columns[1], df.columns[2]])\n",
    "    for i, row in df.iterrows():\n",
    "        if row[df.columns[1]] == df_sep:\n",
    "            splitted_df.append(subdf)\n",
    "            subdf = pd.DataFrame([], columns=[df.columns[1], df.columns[2]])\n",
    "        else:\n",
    "            row = {df.columns[1]:df.iloc[i][1],df.columns[2]:df.iloc[i][2]}\n",
    "            subdf = subdf.append(row, ignore_index = True)\n",
    "    \n",
    "    if len(subdf.index) > 0:\n",
    "        splitted_df.append(subdf)\n",
    "\n",
    "    return splitted_df\n",
    "\n",
    "    \n",
    "def df_to_buffered_jsons_list(dataframe, jsons_list, include_stop=True, buffer_size=3, show=False):\n",
    "          \n",
    "    df = dataframe.reset_index()\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "\n",
    "        if i < buffer_size - 1:\n",
    "            continue\n",
    "\n",
    "        prompt = \"\"\n",
    "        for j in reversed(range(buffer_size)):\n",
    "            if j > 0:\n",
    "                prompt += df.columns[1] + ': ' + df.iloc[i-j][1] + '\\n' + df.columns[2] + ': ' + df.iloc[i-j][2] + '\\n'\n",
    "            else:\n",
    "                prompt += df.columns[1] + ': ' + df.iloc[i-j][1] + '\\n' + df.columns[2] + ':'\n",
    "\n",
    "        completion = ' ' + df.iloc[i][2]\n",
    "        \n",
    "        if include_stop:\n",
    "            completion += '\\n' + df.columns[1] + ': '\n",
    "\n",
    "        if show:\n",
    "            str_prompt = prompt.replace(\"\\n\", \"\\\\n\")\n",
    "            str_completion = completion.replace(\"\\n\", \"\\\\n\")\n",
    "            print(f\"PROMPT:'{str_prompt}' COMPLETION:'{str_completion}'\")\n",
    "\n",
    "        buffered_json = json.dumps({\"prompt\":prompt,\"completion\":completion}, ensure_ascii=False)\n",
    "        jsons_list.append(buffered_json)\n",
    "\n",
    "\n",
    "def jsons_list_to_jsonl(jsons_list, jsonl_path, encoding='utf-8', clear_first=True):\n",
    "    if clear_first:\n",
    "        open(jsonl_path, 'w', encoding=encoding).close() # clear content\n",
    "        \n",
    "    with open(jsonl_path, 'a', encoding=encoding) as outfile:\n",
    "        for json_str in jsons_list:\n",
    "            outfile.write(json_str)\n",
    "            outfile.write('\\n')\n",
    "            \n",
    "            \n",
    "def csv_to_jsonl(csv_path, jsonl_train_path, jsonl_val_path,\n",
    "                 csv_sep=';', df_sep=\"###\", encoding='utf-8',\n",
    "                 include_stop=True, buffer_size=3, train_partition=0.8):\n",
    "    \n",
    "    df_list = csv_to_df_list(csv_path, csv_sep=csv_sep, df_sep=df_sep, encoding=encoding)\n",
    "    print(f'df_list:{len(df_list)}')\n",
    "    jsons_list = []\n",
    "    for df in df_list:\n",
    "        df_to_buffered_jsons_list(df, jsons_list, include_stop=include_stop, buffer_size=3, show=False)\n",
    "    print(f'jsons_list:{len(jsons_list)}')\n",
    "    \n",
    "    random.shuffle(jsons_list)\n",
    "    train, val = np.split(jsons_list, [int(len(jsons_list)*train_partition)])\n",
    "    \n",
    "    jsons_list_to_jsonl(train, jsonl_train_path, encoding=encoding, clear_first=True)\n",
    "    jsons_list_to_jsonl(val, jsonl_val_path, encoding=encoding, clear_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "347a250b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_list:3\n",
      "jsons_list:5\n"
     ]
    }
   ],
   "source": [
    "csv_path = '.\\\\sample_chat.csv'\n",
    "jsonl_train_path = '.\\\\train.jsonl'\n",
    "jsonl_val_path = '.\\\\val.jsonl'\n",
    "\n",
    "include_stop=True\n",
    "buffer_size=3\n",
    "partition=0.8\n",
    "\n",
    "csv_to_jsonl(csv_path, jsonl_train_path, jsonl_val_path,\n",
    "             include_stop=include_stop, buffer_size=buffer_size, train_partition=partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b37d9f8",
   "metadata": {},
   "source": [
    "## Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d5a6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file(file_path, purpose='fine-tune', encoding='utf-8', show=False):\n",
    "    # https://beta.openai.com/docs/api-reference/files/upload\n",
    "    resp = openai.File.create(purpose=purpose, file=open(file_path, encoding=encoding))\n",
    "    if show:\n",
    "        pprint(resp)\n",
    "    return resp\n",
    "\n",
    "\n",
    "def list_files(show=False):\n",
    "    # https://beta.openai.com/docs/api-reference/files/list\n",
    "    resp = openai.File.list()\n",
    "    if show:\n",
    "        pprint(resp)\n",
    "    return resp\n",
    "    \n",
    "\n",
    "def delete_file(file_id, show=False):\n",
    "    # https://beta.openai.com/docs/api-reference/files/delete\n",
    "    resp = openai.File.delete(file_id)\n",
    "    if show:\n",
    "        pprint(resp)\n",
    "    return resp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389a44bb",
   "metadata": {},
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3842d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ft_model(train_file_id, val_file_id=None, suffix=None, model='davinci', show=True):\n",
    "    # https://beta.openai.com/docs/api-reference/fine-tunes/create\n",
    "    resp = openai.FineTune.create(training_file=train_file_id, validation_file=val_file_id, suffix=suffix, model=model)\n",
    "    if show:\n",
    "        pprint(resp)\n",
    "    return resp\n",
    "\n",
    "\n",
    "def list_ft_models(show=False):\n",
    "    # https://beta.openai.com/docs/api-reference/fine-tunes/list\n",
    "    resp = openai.FineTune.list()\n",
    "    if show:\n",
    "        pprint(resp)\n",
    "    return resp\n",
    "    \n",
    "    \n",
    "def retrieve_ft_model(ft_model_id, show=False):\n",
    "    # https://beta.openai.com/docs/api-reference/fine-tunes/retrieve\n",
    "    resp = openai.FineTune.retrieve(id=ft_model_id)\n",
    "    if show:\n",
    "        pprint(resp)\n",
    "    return resp\n",
    "\n",
    "\n",
    "def cancel_ft_job(ft_model_id, show=False):\n",
    "    # https://beta.openai.com/docs/api-reference/fine-tunes/cancel\n",
    "    resp = openai.FineTune.cancel(id=ft_model_id)\n",
    "    if show:\n",
    "        pprint(resp)\n",
    "    return resp\n",
    "\n",
    "\n",
    "def delete_ft_model(ft_model_id, show=False):\n",
    "    # https://beta.openai.com/docs/api-reference/fine-tunes/cancel\n",
    "    resp = openai.FineTune.delete(sid=ft_model_id)\n",
    "    if show:\n",
    "        pprint(resp)\n",
    "    return resp\n",
    "    \n",
    "    \n",
    "def list_ft_events(ft_model_id, show=False):\n",
    "    # https://beta.openai.com/docs/api-reference/fine-tunes/events\n",
    "    resp = openai.FineTune.list_events(id=ft_model_id)\n",
    "    if show:\n",
    "        pprint(resp)\n",
    "    return resp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5665f552",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53773d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_models(owned_by=None, show=False):\n",
    "    # https://beta.openai.com/docs/api-reference/models/list\n",
    "    resp = openai.Model.list()\n",
    "    if owned_by != None:\n",
    "        filtered_models = []\n",
    "        for model in resp['data']:\n",
    "            if model['owned_by'] == owned_by:\n",
    "                filtered_models.append(model)\n",
    "        resp['data'] = filtered_models\n",
    "    if show:\n",
    "        pprint(resp)\n",
    "    return resp\n",
    "\n",
    "\n",
    "def retrieve_model(model_id, show=False):\n",
    "    # https://beta.openai.com/docs/api-reference/models/retrieve\n",
    "    resp = openai.Model.retrieve(model_id)\n",
    "    if show:\n",
    "        pprint(resp)\n",
    "    return resp\n",
    "\n",
    "\n",
    "def delete_model(model_id, show=False):\n",
    "    # https://beta.openai.com/docs/api-reference/fine-tunes/delete-model\n",
    "    resp = openai.Model.delete(model_id)\n",
    "    if show:\n",
    "        pprint(resp)\n",
    "    return resp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4402b97b",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7c34db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_content_policy(input_text, show=False):\n",
    "    # https://beta.openai.com/docs/api-reference/moderations/create\n",
    "    resp = openai.Moderation.create(input=input_text)\n",
    "    if show:\n",
    "        pprint(resp)\n",
    "    return resp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aaed96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_all_files():\n",
    "    file_list = list_files()['data']\n",
    "    for f in file_list:\n",
    "        print(f\"DELETING FILE {f['id']}\")\n",
    "        delete_file(f['id'])\n",
    "    print(\"ALL FILES DELETED\")\n",
    "    \n",
    "    \n",
    "def delete_all_models(org_id):\n",
    "    models = list_models(owned_by=org_id)['data']\n",
    "    for m in models:\n",
    "        print(f\"DELETING MODEL {m['id']}\")\n",
    "        delete_model(m['id'])\n",
    "    print(\"ALL MODELS DELETED\") \n",
    "        \n",
    "        \n",
    "def delete_all_ft_models(try_to_delete=False):\n",
    "    ft_models = list_ft_models()['data']\n",
    "    for ft in ft_models:\n",
    "        if ft['status'] != 'succeeded' and ft['status'] != 'cancelled':\n",
    "            print(f\"TRYING TO CANCEL FT MODEL {ft['id']}\")\n",
    "            cancel_ft_job(ft['id'])\n",
    "        else:\n",
    "            if try_to_delete:\n",
    "                try:\n",
    "                    print(f\"TRYING TO DELETE FT MODEL {ft['id']}\")\n",
    "                    delete_ft_model(ft['id'])\n",
    "                except:\n",
    "                    print(f\"NOT ALLOWED\")\n",
    "    if try_to_delete:\n",
    "        print(\"ALL FINE TUNINING JOBS DELETED\")\n",
    "    else:\n",
    "        print(\"ALL FINE TUNINING JOBS CANCELED OR SUCCEEDED\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1129100d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listen_job_events(ft_model_id, every_seconds=1.0):\n",
    "    latest_msg = \"\"\n",
    "    while True:\n",
    "        events = openai.FineTune.list_events(id=ft_model_id)['data']\n",
    "        str_time = datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "        if len(events) > 0:\n",
    "            latest_event = events[len(events)-1]\n",
    "            if \"succeeded\" in latest_event['message']:\n",
    "                print(\"\",end='\\n')\n",
    "                print(f\"[{str_time}] Job succeeded!\")\n",
    "                return\n",
    "            elif latest_msg != latest_event['message']:\n",
    "                latest_msg = latest_event['message']\n",
    "                print(\"\",end='\\n')\n",
    "                print(f\"[{str_time}] Event: {latest_msg}\", end='\\r')\n",
    "            else:\n",
    "                print(f\"[{str_time}] Event: {latest_msg}\", end='\\r')\n",
    "        else:\n",
    "          print(f'Waiting for new events...', end='\\r')\n",
    "        time.sleep(every_seconds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757986eb",
   "metadata": {},
   "source": [
    "## Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c9d1fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_list = list_files(show=True)\n",
    "model_list = list_models(owned_by=org_id, show=True)\n",
    "#ft_models_list = list_ft_models()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599fde2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: Destructive operations!\n",
    "\n",
    "#delete_all_ft_models()\n",
    "#delete_all_files()\n",
    "#delete_all_models(org_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c035aea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_info = upload_file(jsonl_train_path)\n",
    "train_file_id = train_file_info['id']\n",
    "\n",
    "val_file_info = upload_file(jsonl_val_path)\n",
    "val_file_id = val_file_info['id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c44440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model_creation = create_ft_model(train_file_id, val_file_id=val_file_id, suffix='my_fine_tuned_model', model='davinci')\n",
    "ft_model_id = ft_model_creation['id']\n",
    "listen_job_events(ft_model_id, every_seconds=1.0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
